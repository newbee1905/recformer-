import argparse
import subprocess
import sys
from pathlib import Path

SLURM_SCRIPT_TEMPLATE = """#!/bin/bash
#
# This script is auto-generated by train_slurm_multi.py. Do not edit manually.
#
#SBATCH --job-name={job_name}
#SBATCH --account={account}
#SBATCH --partition={partition}
#SBATCH --cpus-per-task=8
#SBATCH --output=logs/%x.%j.out
#SBATCH --error=logs/%x.%j.err
#SBATCH --mail-type=ALL
#SBATCH --mail-user={mail_user}

set -euo pipefail

# --- Environment Setup ---
echo "Loading modules..."

module load cuda/11.8.0
source .venv/bin/activate

export PYTHONPATH=.

# --- DDP Setup ---
export MASTER_ADDR=$(scontrol show hostname $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=$(shuf -i 29500-65535 -n 1)
GPUS_PER_NODE={num_gpus}

# --- Job Info & Execution ---
OUTPUT_DIR="outputs/${{SLURM_JOB_NAME}}/${{SLURM_JOB_ID}}"
echo "--- Job Info ---"
echo "Starting SLURM job $SLURM_JOB_ID on $(hostname)"
echo "Model Config: {model_config}"
echo "Output Dir: $OUTPUT_DIR"
echo "Master Node: $MASTER_ADDR, Port: $MASTER_PORT"
echo "GPUs per node: $GPUS_PER_NODE"
echo "Nodes: {num_nodes}"
echo "Hydra args: {hydra_args_str}"
echo "----------------"
nvidia-smi

# --- Training ---
echo "Starting training run..."
srun torchrun \
	--nproc_per_node=$GPUS_PER_NODE \
	--nnodes=$SLURM_NNODES \
	--rdzv_id=$SLURM_JOB_ID \
	--rdzv_backend=c10d \
	--rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
	main.py model={model_config} hydra.run.dir=$OUTPUT_DIR {hydra_args_str}
echo "Training finished."

# --- Evaluation ---
if [ "{run_eval}" = "True" ]; then
    echo "Starting evaluation..."
    # We only need to run this on a single process, not with srun/torchrun
    if [ "$SLURM_PROCID" -eq 0 ]; then
        python scripts/lm_eval.py checkpoint_dir=$OUTPUT_DIR
    fi
    echo "Evaluation finished."
fi

echo "SLURM job $SLURM_JOB_ID finished."
"""


def main():
	"""Parses arguments, generates SLURM scripts for multiple configs, and submits them."""
	parser = argparse.ArgumentParser(
		description="Generate and submit multiple SLURM jobs for training different model configurations.",
		formatter_class=argparse.RawTextHelpFormatter,
		usage="python %(prog)s --model_configs <config1> <config2> ... [options] -- [hydra_options]",
	)

	# SLURM arguments
	slurm_group = parser.add_argument_group("SLURM Configuration")
	slurm_group.add_argument(
		"--model_configs",
		type=str,
		nargs="+",
		required=True,
		help="List of model configs in config/model (e.g., 'recurrent_small' 'gpt2').",
	)
	slurm_group.add_argument("--num_gpus", type=int, default=1, help="Number of GPUs to request per node.")
	slurm_group.add_argument("--account", type=str, default="matsim_acc23", help="SLURM account to use.")
	slurm_group.add_argument("--partition", type=str, default="gpu", help="SLURM partition to use.")
	slurm_group.add_argument("--num_nodes", type=int, default=1, help="Number of nodes to request.")
	slurm_group.add_argument(
		"--job_name_prefix", type=str, default="train", help="Prefix for job names. Defaults to 'train'."
	)
	slurm_group.add_argument("--mail_user", type=str, default="your_email@example.com", help="Email for notifications.")

	# Script behavior arguments
	action_group = parser.add_argument_group("Script Actions")
	action_group.add_argument(
		"--dry_run",
		action="store_true",
		help="Print the generated scripts to stdout instead of submitting them to sbatch.",
	)
	action_group.add_argument(
		"--no-eval",
		action="store_false",
		dest="run_eval",
		help="Do not run lm-eval-harness after training. Evaluation runs by default.",
	)
	parser.set_defaults(run_eval=True)

	# All arguments after '--' will be treated as hydra arguments
	args, hydra_args = parser.parse_known_args()
	if hydra_args and hydra_args[0] == "--":
		hydra_args = hydra_args[1:]

	hydra_args_str = " ".join(hydra_args)

	for model_config in args.model_configs:
		job_name = f"{args.job_name_prefix}-{model_config}"

		slurm_script_content = SLURM_SCRIPT_TEMPLATE.format(
			model_config=model_config,
			num_gpus=args.num_gpus,
			account=args.account,
			partition=args.partition,
			num_nodes=args.num_nodes,
			job_name=job_name,
			mail_user=args.mail_user,
			hydra_args_str=hydra_args_str,
			run_eval=args.run_eval,
		)

		if args.dry_run:
			print(f"--- Generated SLURM Script for {model_config} (Dry Run) ---")
			print(slurm_script_content)
			print("-" * 50)
			continue

		print(f"Submitting job '{job_name}' for model '{model_config}' to SLURM...")
		try:
			# Use subprocess.run to pipe the script content to sbatch
			process = subprocess.run(["sbatch"], input=slurm_script_content, text=True, capture_output=True, check=True)
			print("Job submitted successfully!")
			print(process.stdout.strip())
			if process.stderr:
				print("sbatch stderr:", process.stderr, file=sys.stderr)

		except FileNotFoundError:
			print("Error: 'sbatch' command not found. Are you on a SLURM login node?", file=sys.stderr)
			sys.exit(1)
		except subprocess.CalledProcessError as e:
			print(f"Error submitting job to SLURM (exit code {e.returncode}):", file=sys.stderr)
			print(e.stdout, file=sys.stdout)
			print(e.stderr, file=sys.stderr)
			sys.exit(1)


if __name__ == "__main__":
	main()
