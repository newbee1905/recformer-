import argparse
import subprocess
import sys
from pathlib import Path

SLURM_SCRIPT_TEMPLATE = """#!/bin/bash
#
# This script is auto-generated by train_slurm.py. Do not edit manually.
#
#SBATCH --job-name={job_name}
#SBATCH --account={account}
#SBATCH --partition={partition}
#SBATCH --cpus-per-task=8
#SBATCH --output=logs/%x.%j.out
#SBATCH --error=logs/%x.%j.err
#SBATCH --mail-type=ALL
#SBATCH --mail-user={mail_user}

set -euo pipefail

# --- Environment Setup ---
echo "Loading modules..."

module load cuda/11.8.0
source .venv/bin/activate

export PYTHONPATH=.

# --- DDP Setup ---
export MASTER_ADDR=$(scontrol show hostname $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=$(shuf -i 29500-65535 -n 1)
GPUS_PER_NODE={num_gpus}

# --- Job Info & Execution ---
OUTPUT_DIR="outputs/${{SLURM_JOB_NAME}}/${{SLURM_JOB_ID}}"
echo "--- Job Info ---"
echo "Starting SLURM job $SLURM_JOB_ID on $(hostname)"
echo "Model Config: {model_config}"
echo "Output Dir: $OUTPUT_DIR"
echo "Master Node: $MASTER_ADDR, Port: $MASTER_PORT"
echo "GPUs per node: $GPUS_PER_NODE"
echo "Nodes: {num_nodes}"
echo "Hydra args: {hydra_args_str}"
echo "----------------"

# --- GPU Monitoring Setup ---
mkdir -p ${{OUTPUT_DIR}}
GPU_LOG="${{OUTPUT_DIR}}/gpu_monitoring.csv"
echo "timestamp, gpu_util, mem_used, mem_total" > "$GPU_LOG" # Create header once

(
    while true; do
        # Queries timestamp, utilization, and memory usage in CSV format
        nvidia-smi --query-gpu=timestamp,utilization.gpu,memory.used,memory.total \
            --format=csv,noheader,nounits >> "$GPU_LOG"
        sleep 15
    done
) &
MONITOR_PID=$!

# --- Training ---
echo "Starting training run..."
srun torchrun \
	--nproc_per_node=$GPUS_PER_NODE \
	--nnodes=$SLURM_NNODES \
	--rdzv_id=$SLURM_JOB_ID \
	--rdzv_backend=c10d \
	--rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
	main.py model={model_config} hydra.run.dir=$OUTPUT_DIR {hydra_args_str}
echo "Training finished."

# --- Kill Monitoring ---
echo "Stopping GPU monitoring (PID: $MONITOR_PID)..."
kill $MONITOR_PID

# --- Evaluation ---
if [ "{run_eval}" = "True" ]; then
    echo "Starting evaluation..."
    # We only need to run this on a single process, not with srun/torchrun
    if [ "$SLURM_PROCID" -eq 0 ]; then
        python scripts/lm_eval.py checkpoint_dir=$OUTPUT_DIR
    fi
    echo "Evaluation finished."
fi

echo "SLURM job $SLURM_JOB_ID finished."
"""


def main():
	"""Parses arguments, generates a SLURM script, and submits it."""
	parser = argparse.ArgumentParser(
		description="Generate and submit a SLURM job for training the model.",
		formatter_class=argparse.RawTextHelpFormatter,
		usage="python %(prog)s --model_config <config> [options] -- [hydra_options]",
	)

	# SLURM arguments
	slurm_group = parser.add_argument_group("SLURM Configuration")
	slurm_group.add_argument(
		"--model_config",
		type=str,
		required=True,
		help="Name of the model config in config/model (e.g., 'recurrent_small').",
	)
	slurm_group.add_argument("--num_gpus", type=int, default=1, help="Number of GPUs to request per node.")
	slurm_group.add_argument("--account", type=str, default="matsim_acc23", help="SLURM account to use.")
	slurm_group.add_argument("--partition", type=str, default="gpu", help="SLURM partition to use.")
	slurm_group.add_argument("--num_nodes", type=int, default=1, help="Number of nodes to request.")
	slurm_group.add_argument("--job_name", type=str, default=None, help="Job name. Defaults to 'train-<model_config>'.")
	slurm_group.add_argument("--mail_user", type=str, default="your_email@example.com", help="Email for notifications.")

	# Script behavior arguments
	action_group = parser.add_argument_group("Script Actions")
	action_group.add_argument(
		"--dry_run",
		action="store_true",
		help="Print the generated script to stdout instead of submitting it to sbatch.",
	)
	action_group.add_argument(
		"--no-eval",
		action="store_false",
		dest="run_eval",
		help="Do not run lm-eval-harness after training. Evaluation runs by default.",
	)
	parser.set_defaults(run_eval=True)

	# All arguments after '--' will be treated as hydra arguments
	args, hydra_args = parser.parse_known_args()
	if hydra_args and hydra_args[0] == "--":
		hydra_args = hydra_args[1:]

	if args.job_name is None:
		args.job_name = f"train-{args.model_config}"

	hydra_args_str = " ".join(hydra_args)

	slurm_script_content = SLURM_SCRIPT_TEMPLATE.format(
		model_config=args.model_config,
		num_gpus=args.num_gpus,
		account=args.account,
		partition=args.partition,
		num_nodes=args.num_nodes,
		job_name=args.job_name,
		mail_user=args.mail_user,
		hydra_args_str=hydra_args_str,
		run_eval=args.run_eval,
	)

	if args.dry_run:
		print("--- Generated SLURM Script (Dry Run) ---")
		print(slurm_script_content)
		return

	print(f"Submitting job '{args.job_name}' to SLURM...")
	try:
		# Use subprocess.run to pipe the script content to sbatch
		process = subprocess.run(["sbatch"], input=slurm_script_content, text=True, capture_output=True, check=True)
		print("Job submitted successfully!")
		print(process.stdout.strip())
		if process.stderr:
			print("sbatch stderr:", process.stderr, file=sys.stderr)

	except FileNotFoundError:
		print("Error: 'sbatch' command not found. Are you on a SLURM login node?", file=sys.stderr)
		sys.exit(1)
	except subprocess.CalledProcessError as e:
		print(f"Error submitting job to SLURM (exit code {e.returncode}):", file=sys.stderr)
		print(e.stdout, file=sys.stdout)
		print(e.stderr, file=sys.stderr)
		sys.exit(1)


if __name__ == "__main__":
	main()
